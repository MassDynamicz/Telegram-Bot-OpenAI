import { Telegraf, session, Markup } from 'telegraf'
import { message } from 'telegraf/filters'
import { code } from 'telegraf/format'
import config from 'config'
import { ogg } from './ogg.js'
import { openai } from './openai.js'
import { getTypingOptions } from './utils.js'

const INITIAL_SESSION = {
  messages: []
}

const bot = new Telegraf(config.get('TELEGRAM_TOKEN'))

const mainMenuKeyboard = Markup.inlineKeyboard([
  Markup.button.callback('ðŸ’¬Ð¢ÐµÐºÑÑ‚ Ð¸Ð»Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ', 'text_voice_input'),
  Markup.button.callback('Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ', 'image_recognation'),
]);


bot.use(session())


bot.command('start', async (ctx) => {
  ctx.session = INITIAL_SESSION
  await ctx.reply('ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽ, Ñ‡ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?', mainMenuKeyboard);
})
bot.action('text_voice_input', async (ctx) => {
  ctx.session ??= INITIAL_SESSION
  await ctx.reply('ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ Ð¸Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ')
})
bot.on(message('voice'), async ctx => {
  ctx.session ??= INITIAL_SESSION
  try {
    await ctx.reply(code('Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾, Ð¶Ð´ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð° ...ðŸ£'))
    await ctx.replyWithChatAction('typing')
    const link = await ctx.telegram.getFileLink(ctx.message.voice.file_id)
    const userId = String(ctx.message.from.id)
    const oggPath = await ogg.create(link.href, userId)
    const mp3Path = await ogg.toMP3(oggPath, userId)
    const text = await openai.transcription(mp3Path)
    await ctx.reply(code(`Ð’Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ: ${text}`))

    ctx.session.messages.push({ role: openai.roles.USER, content: text })

    const response = await openai.chat(ctx.session.messages)

    ctx.session.messages.push({
      role: openai.roles.ASSISTANT,
      content: response.content
    })

    await ctx.reply(response.content)

  } catch (e) {
    console.log('Error: voice msg', e.message);
  }
})

bot.on(message('text'), async ctx => {
  ctx.session ??= INITIAL_SESSION
  try {
    await ctx.reply(code('Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾, Ð¶Ð´ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð° ...ðŸ£'))
    await ctx.replyWithChatAction('typing')

    ctx.session.messages.push({ role: openai.roles.USER, content: ctx.message.text })

    const response = await openai.chat(ctx.session.messages)

    ctx.session.messages.push({
      role: openai.roles.ASSISTANT,
      content: response.content
    })

    await ctx.reply(`ÐžÑ‚Ð²ÐµÑ‚: ${response.content}`)

  } catch (e) {
    console.log('Error: text', e.message)
  }
})
bot.command('new', async (ctx) => {
  ctx.session = INITIAL_SESSION
  await ctx.reply('Ð–Ð´Ñƒ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ Ð¸Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ')
})



bot.action('image_recognation', async (ctx) => {
  ctx.session ??= INITIAL_SESSION
  await ctx.reply('Ð­Ñ‚Ð° Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ')
})

bot.launch()

process.once('SIGINT', () => bot.stop('SIGINT'))
process.once('SIGTERM', () => bot.stop('SIGTERM'))